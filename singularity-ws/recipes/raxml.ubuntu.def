#-------------------------------------------------------------------------------
#  \author Jan P Buchmann <jan.buchmann@sydney.edu.au>
#  \description Singularity recipe for ABACBS 2018 Docker Workshop
#-------------------------------------------------------------------------------

# Header: Mandatory
#   - Which OS to use as containr base
#   - Configuration of the base system
#   E.g. which Linux distribution, versions and wich packages are part of the
#        core install
Bootstrap: shub # Mandatory: Which base to use, e.g. docker, shub, ..
From: singularityhub/ubuntu

# Sections : Optional
# defined by '%' and followed by its name. Use to control the build process and
# container setup

##  %help section
#    Add a message describing the container's usage or purpose
%help
This is a simple demonrations of deploying RAxML in a Singularity container
Add usage later

##  %setup section
#    Commands executed on the host system after the installation of the base OS,
#    but before %post. Runs as root user.
#    If using Singularity < 2.3, this is the point to move files into the
#    container required by %post. For Singularity >= 2.3, use %files section to
#    copy files reuiqred by %post
#%setup
#  sed -i \
#      -e 's%http://archive.ubuntu.com/ubuntu%mirror://mirrors.ubuntu.com/mirrors.txt%' \
#      -e 's/^deb-src/#deb-src/' /etc/apt/sources.list
  #mkdir -p ${SINGULARITY_ROOTFS}/tmp/build/cont_build

##  %files section
#    Copy files from host to container before post
#%files


##  %labels section
#    Add Metadata to the container in the form of LABELNAME LABELVALUE
%labels
  Maintainer jpb
  Contact jan.buchmann@sydney.edu.au
  Version 0.1.0

##  %enviroment section
#     Enviroment variables are sourced during run time, not build time.
#     Use same conventions as in .bashrc, .profile, etc.
#     Set enviroment variabels required for build in %post, not here.
#     However, echo 'export MYVAR=iamthewalrus' >> $SINGULARITY_ENVIRONMENT will
#     export during %post.
export PATH=/bin:/usr/bin:/usr/local/bin:/usr/local/cuda/bin:

## % post section
#   All commnads are run during build time in the containre after installing the
#   base OS. At this point, files cannot be copied from host to the container,
#   but using git, wget, curl, scp, etc. will work. Runs as root.
#   If you want to use mutiple nodes on an HPC enviroment, you need to make
#   sure that your system has MPI installed.
%post
  apt-get -q update
  apt-get -y  --no-install-recommends install git openssl ca-certificates  \
   openssh-server build-essential openmpi-bin openmpi-common  libopenmpi-dev mpi-default-dev
  
  apt-get clean && apt-get autoremove
  rm -rf /var/lib/apt/lists/*

  ### destination for HPC bind mounts
  mkdir -p /project /scratch
  touch /usr/bin/nvidia-smi
  cd /tmp/
  if [ -d standard-RAxML ]; then
    cd standard-RAxML
    git pull
  else
    git clone https://github.com/stamatak/standard-RAxML.git
    cd standard-RAxML
  fi
  make -j2 -f Makefile.AVX.HYBRID.gcc
  rm *.o
  mv raxmlHPC-HYBRID-AVX /usr/local/bin
  chmod +x /usr/local/bin/raxmlHPC-HYBRID-AVX

## %runscript section
#   %runscript is not executed during build,but called upon running the
#   singularity image, analogous to Docker's CMD or ENTRYPOINT.
#   Handle argumnet processing etc.
%runscript
  exec raxmlHPC-HYBRID-AVX  "$@"

%test
 # raxmlHPC-HYBRID-AVX -v

## %startscript section
#   Define what to do if started as an instance
#%startscript
